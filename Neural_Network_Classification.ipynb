{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMWMdO2sJBFsuBiJ+T/Qtos",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karimrd-hub/Classification-using-Neural-Networks/blob/main/Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHkUsrzPfR5Z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import datetime\n",
        "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create data to make some practice"
      ],
      "metadata": {
        "id": "DdXhGz5dfY76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# Make 1000 examples\n",
        "n_samples = 1000\n",
        "\n",
        "# Create circles\n",
        "X, y = make_circles(n_samples,\n",
        "                    noise=0.03,\n",
        "                    random_state=42)"
      ],
      "metadata": {
        "id": "W1gmIwWsfYO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "W5T7a9q5fqun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[:10]"
      ],
      "metadata": {
        "id": "_vVoj43QfrW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "circles = pd.DataFrame({\"X0\":X[:, 0], \"X1\":X[:, 1], \"label\":y})\n",
        "circles.head()"
      ],
      "metadata": {
        "id": "clS189pbf17g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the labels\n",
        "circles.label.value_counts()"
      ],
      "metadata": {
        "id": "sknEufpYgHth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize with a plot\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X[:, 0], X[:,1], c=y, cmap=plt.cm.RdYlBu)"
      ],
      "metadata": {
        "id": "9ZYhKW90gMo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shapes of our features and labels\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "b9VFC3G-gu5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many samples we have\n",
        "len(X), len(y)"
      ],
      "metadata": {
        "id": "OMuTXUOMg7mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0]"
      ],
      "metadata": {
        "id": "qPJo_MC5g--2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps in modeling"
      ],
      "metadata": {
        "id": "ejfyq-ASlg6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "#create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Fit\n",
        "model_1.fit(X, y, epochs=5)\n"
      ],
      "metadata": {
        "id": "bdu4KG_Kljlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# increase the number of epochs because the accuracy of our modle is only 50%\n",
        "model_1.fit(X, y, epochs=200, verbose=0)\n",
        "model_1.evaluate(X, y)"
      ],
      "metadata": {
        "id": "BIswY3hXmOoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The accucary didn't improve so what about adding extra layers and train for a little bit longer?\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model (\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1), # add an extra layer\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile\n",
        "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# 3. Fit\n",
        "model_2.fit(X, y, epochs=100, verbose=0)"
      ],
      "metadata": {
        "id": "71V1rIsmmpFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(X, y)"
      ],
      "metadata": {
        "id": "B5eORKCWnLQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improving a model"
      ],
      "metadata": {
        "id": "xjMdUoSIgZuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model (this time 3 layers)\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100), # add 100 dense neurons\n",
        "  tf.keras.layers.Dense(10), # add another layer with 10 neurons\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(), # use Adam instead of SGD\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_3.fit(X, y, epochs=100, verbose=1)"
      ],
      "metadata": {
        "id": "bR1q0A7-gbfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def plot_decision_boundary(model, X, y):\n",
        "  # Define the axis boundaries of the plot and create a meshgrid\n",
        "  x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "  y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
        "  xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                       np.linspace(y_min, y_max, 100))\n",
        "\n",
        "  # Create X values (we're going to predict on all of these)\n",
        "  x_in = np.c_[xx.ravel(), yy.ravel()] # stack 2D arrays together: https://numpy.org/devdocs/reference/generated/numpy.c_.html\n",
        "\n",
        "  # Make predictions using the trained model\n",
        "  y_pred = model.predict(x_in)\n",
        "\n",
        "  # Check for multi-class\n",
        "  if model.output_shape[-1] > 1: # checks the final dimension of the model's output shape, if this is > (greater than) 1, it's multi-class\n",
        "    print(\"doing multiclass classification...\")\n",
        "    # We have to reshape our predictions to get them ready for plotting\n",
        "    y_pred = np.argmax(y_pred, axis=1).reshape(xx.shape)\n",
        "  else:\n",
        "    print(\"doing binary classifcation...\")\n",
        "    y_pred = np.round(np.max(y_pred, axis=1)).reshape(xx.shape)\n",
        "\n",
        "  # Plot decision boundary\n",
        "  plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n",
        "  plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
        "  plt.xlim(xx.min(), xx.max())\n",
        "  plt.ylim(yy.min(), yy.max())"
      ],
      "metadata": {
        "id": "ecnOTSXGiDFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the predictions our model is making\n",
        "plot_decision_boundary(model_3, X, y)"
      ],
      "metadata": {
        "id": "iQjIaM0r1VEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The missing piece: Non-linearity"
      ],
      "metadata": {
        "id": "EA2c-CIUVuss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The main change in this model compared to the previous model is the 'activation' keyword\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_4 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1, activation=tf.keras.activations.linear), # 1 hidden layer with linear activation\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_4.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model_4.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "id": "Y23RL2Z0V2AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_boundary(model_4, X, y)"
      ],
      "metadata": {
        "id": "QvXCDvIYaSTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To deal with the non-linearity of the data we can add a non-linear activation of the model"
      ],
      "metadata": {
        "id": "dgPtgytUaxUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model with a non-linear activation\n",
        "model_5 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1, activation=tf.keras.activations.relu),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_5.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model_5.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "id": "2rCGMTyQa9Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is still not learning, let's try to add more hidden layers with more neurons per layer"
      ],
      "metadata": {
        "id": "RBrmXrs4bbRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model\n",
        "model_6 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 1, 4 neurons, ReLU activation\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 2, 4 neurons, ReLU activation\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_6.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "history = model_6.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "id": "5_PXXmk6biD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.evaluate(X, y)"
      ],
      "metadata": {
        "id": "nBFw8bBebxHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_boundary(model_6, X, y)"
      ],
      "metadata": {
        "id": "u_L32IOdcMFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy increased to 60%\n",
        "\n",
        "Let's try modifying the activation of the hidden layers and the output layer"
      ],
      "metadata": {
        "id": "6EEPoxcmceln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model\n",
        "model_7 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 1, ReLU activation\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 2, ReLU activation\n",
        "  tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid) # ouput layer, sigmoid activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "history = model_7.fit(X, y, epochs=100, verbose=0)"
      ],
      "metadata": {
        "id": "3UmCYWkectbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.evaluate(X, y)"
      ],
      "metadata": {
        "id": "BN4HpH00c1pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_boundary(model_7, X, y)"
      ],
      "metadata": {
        "id": "PyHEATZXlAyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great results: now it seems like our models is capable of separating the 2 circles properly"
      ],
      "metadata": {
        "id": "j3E60OcPm5WD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating and improving our classification model"
      ],
      "metadata": {
        "id": "9eybmXAxwJNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "id": "t0RmgkcfwKjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, y_train = X[:800], y[:800]\n",
        "X_test, y_test = X[800:], y[800:]\n",
        "\n",
        "# check the shapes of the data\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "GXLtKI-4wOpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RUOBhA1g8Kx"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_8 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_8.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), # increase learning rate from 0.001 to 0.01 for faster learning\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "history = model_8.fit(X_train, y_train, epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate  our model on the test set\n",
        "loss, accuracy = model_8.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "4OoWiPlixCyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decision boundaries for the training and test sets\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Train\")\n",
        "plot_decision_boundary(model_8, X=X_train, y=y_train)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Test\")\n",
        "plot_decision_boundary(model_8, X=X_test, y=y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HakaXp_TxmaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the loss curves"
      ],
      "metadata": {
        "id": "Glyr2LVyyhU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the loss and accuracy for every epoch\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.title(\"Model_8 training curves\")"
      ],
      "metadata": {
        "id": "FMDTSGDGyj8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the ideal plot we'd be looking for when dealing with a classification problem, loss going down, accuracy going up\n"
      ],
      "metadata": {
        "id": "-Oc72AC81Aof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the best learning rate"
      ],
      "metadata": {
        "id": "ixlvg0A71Nn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model\n",
        "model_9 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_9.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Create a learning rate scheduler callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # traverse a set of learning rate values starting from 1e-4, increasing by 10**(epoch/20) every epoch\n",
        "\n",
        "# Fit the model\n",
        "history = model_9.fit(X_train,\n",
        "                      y_train,\n",
        "                      epochs=100,\n",
        "                      callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "dEblqNEY1Qde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(10,7), xlabel=\"epochs\");"
      ],
      "metadata": {
        "id": "Z4EXYwWqPPrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning rate versus the loss\n",
        "lrs = 1e-4 * (10 ** (np.arange(100)/20))\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.semilogx(lrs, history.history[\"loss\"]) # we want the x-axis (learning rate) to be log scale\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Learning rate vs. loss\");"
      ],
      "metadata": {
        "id": "OnBb4-pqTBfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To figure out the ideal value of the learning rate (at least the ideal value to *begin* training our model), the rule of thumb is to take the learning rate value where the loss is still decreasing but not quite flattened out (usually about 10x smaller than the bottom of the curve).\n",
        "\n",
        "In this case, our ideal learning rate ends up between `0.01` ($10^{-2}$) and `0.02`."
      ],
      "metadata": {
        "id": "QvMZjYrnUOkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_10 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model with the ideal learning rate\n",
        "model_10.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.02),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model for 20 epochs (5 less than before)\n",
        "history = model_10.fit(X_train, y_train, epochs=20)"
      ],
      "metadata": {
        "id": "yn1uwf-wUPYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "awSBs4H-Uf1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decision boundaries for the training and test sets\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Train\")\n",
        "plot_decision_boundary(model_10, X=X_train, y=y_train)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Test\")\n",
        "plot_decision_boundary(model_10, X=X_test, y=y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nvlmWjYFUie_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excellent results"
      ],
      "metadata": {
        "id": "E012GfanUzPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the accuracy of our model\n",
        "loss, accuracy = model_10.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on test set: {loss}\")\n",
        "print(f\"Model accuracy on test set: {(accuracy*100):.2f}%\")"
      ],
      "metadata": {
        "id": "0u1eco-JRUE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Make predictions\n",
        "y_preds = model_10.predict(X_test)\n",
        "\n",
        "# Create confusion matrix\n",
        "confusion_matrix(y_test, tf.round(y_preds))"
      ],
      "metadata": {
        "id": "ZSpaVg-0RVbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to make the confusion matrix more visual\n",
        "import itertools\n",
        "\n",
        "figsize = (10, 10)\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_test, tf.round(y_preds))\n",
        "cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "n_classes = cm.shape[0]\n",
        "\n",
        "# Let's prettify it\n",
        "fig, ax = plt.subplots(figsize=figsize)\n",
        "# Create a matrix plot\n",
        "cax = ax.matshow(cm, cmap=plt.cm.Blues) # https://matplotlib.org/3.2.0/api/_as_gen/matplotlib.axes.Axes.matshow.html\n",
        "fig.colorbar(cax)\n",
        "\n",
        "# Create classes\n",
        "classes = False\n",
        "\n",
        "if classes:\n",
        "  labels = classes\n",
        "else:\n",
        "  labels = np.arange(cm.shape[0])\n",
        "\n",
        "# Label the axes\n",
        "ax.set(title=\"Confusion Matrix\",\n",
        "       xlabel=\"Predicted label\",\n",
        "       ylabel=\"True label\",\n",
        "       xticks=np.arange(n_classes),\n",
        "       yticks=np.arange(n_classes),\n",
        "       xticklabels=labels,\n",
        "       yticklabels=labels)\n",
        "\n",
        "# Set x-axis labels to bottom\n",
        "ax.xaxis.set_label_position(\"bottom\")\n",
        "ax.xaxis.tick_bottom()\n",
        "\n",
        "# Adjust label size\n",
        "ax.xaxis.label.set_size(20)\n",
        "ax.yaxis.label.set_size(20)\n",
        "ax.title.set_size(20)\n",
        "\n",
        "# Set threshold for different colors\n",
        "threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "# Plot the text on each cell\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "  plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "           horizontalalignment=\"center\",\n",
        "           color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "           size=15)"
      ],
      "metadata": {
        "id": "nMhQ8tSSR8eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems our model did great predictions on the test set"
      ],
      "metadata": {
        "id": "VXNLTIsOSVwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiclass classification"
      ],
      "metadata": {
        "id": "U5Y381iHSQOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# The data has already been sorted into training and test sets for us\n",
        "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "jiErZgQ3Sd90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of our data\n",
        "train_data.shape, train_labels.shape, test_data.shape, test_labels.shape"
      ],
      "metadata": {
        "id": "ii0B-YleS5xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape of a single example\n",
        "train_data[0].shape, train_labels[0].shape"
      ],
      "metadata": {
        "id": "EWgG09XIS7NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a single example\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_data[7]);"
      ],
      "metadata": {
        "id": "4RCqaGsATCTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check our samples label\n",
        "train_labels[7]"
      ],
      "metadata": {
        "id": "stGmBtkiTHkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instead of getting labels as digits let's transform them into english language labels\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "len(class_names)"
      ],
      "metadata": {
        "id": "gKM8nWZRTsgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot an example image and its label\n",
        "plt.imshow(train_data[17], cmap=plt.cm.binary) # change the colours to black & white\n",
        "plt.title(class_names[train_labels[17]]);"
      ],
      "metadata": {
        "id": "CdCl4G9tT2PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot multiple random images of fashion MNIST\n",
        "import random\n",
        "plt.figure(figsize=(7, 7))\n",
        "for i in range(4):\n",
        "  ax = plt.subplot(2, 2, i + 1)\n",
        "  rand_index = random.choice(range(len(train_data)))\n",
        "  plt.imshow(train_data[rand_index], cmap=plt.cm.binary)\n",
        "  plt.title(class_names[train_labels[rand_index]])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "9jd2nKppT-wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_11 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_11.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), # different loss function for multiclass classifcation\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "non_norm_history = model_11.fit(train_data,\n",
        "                                train_labels,\n",
        "                                epochs=10,\n",
        "                                validation_data=(test_data, test_labels))"
      ],
      "metadata": {
        "id": "ynR_RbCMVopb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_11.summary()"
      ],
      "metadata": {
        "id": "Q9I74OVqWNoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well the accuracy is really low (same as guessing) so to improve it we will try to the features and labels between 0 and 1"
      ],
      "metadata": {
        "id": "2-qrfiPWWsU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.min(), train_data.max()"
      ],
      "metadata": {
        "id": "YlubUlsaWQvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide train and test images by the maximum value (normalize it)\n",
        "train_data = train_data / 255.0\n",
        "test_data = test_data / 255.0\n",
        "\n",
        "# Check the min and max values of the training data\n",
        "train_data.min(), train_data.max()"
      ],
      "metadata": {
        "id": "VAGEBOELWYH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_12 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_12.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "norm_history = model_12.fit(train_data,\n",
        "                            train_labels,\n",
        "                            epochs=10,\n",
        "                            validation_data=(test_data, test_labels))"
      ],
      "metadata": {
        "id": "7YZ2y-v6WcIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Plot non-normalized data loss curves\n",
        "pd.DataFrame(non_norm_history.history).plot(title=\"Non-normalized Data\")\n",
        "# Plot normalized data loss curves\n",
        "pd.DataFrame(norm_history.history).plot(title=\"Normalized data\");"
      ],
      "metadata": {
        "id": "2dNzB51lXA-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's try to find the ideal learning rate\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_13 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_13.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# Create the learning rate callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-3 * 10**(epoch/20))\n",
        "\n",
        "# Fit the model\n",
        "find_lr_history = model_13.fit(train_data,\n",
        "                               train_labels,\n",
        "                               epochs=40,\n",
        "                               validation_data=(test_data, test_labels),\n",
        "                               callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "CWs7woVaXwco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning rate decay curve\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "lrs = 1e-3 * (10**(np.arange(40)/20))\n",
        "plt.semilogx(lrs, find_lr_history.history[\"loss\"]) # want the x-axis to be log-scale\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Finding the ideal learning rate\");"
      ],
      "metadata": {
        "id": "7H49vLbMZeA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's refit the model using the ideal learning rate\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_14 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_14.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model_14.fit(train_data,\n",
        "                       train_labels,\n",
        "                       epochs=20,\n",
        "                       validation_data=(test_data, test_labels))"
      ],
      "metadata": {
        "id": "kcLwKaW0Zr3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15):\n",
        "    \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "    If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "    will be used.\n",
        "\n",
        "    Args:\n",
        "      y_true: Array of truth labels (must be same shape as y_pred).\n",
        "      y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "      classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "      figsize: Size of output figure (default=(10, 10)).\n",
        "      text_size: Size of output figure text (default=15).\n",
        "\n",
        "    Returns:\n",
        "      A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "    Example usage:\n",
        "      make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                            y_pred=y_preds, # predicted labels\n",
        "                            classes=class_names, # array of class label names\n",
        "                            figsize=(15, 15),\n",
        "                            text_size=10)\n",
        "    \"\"\"\n",
        "    # Create the confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]  # normalize it\n",
        "    n_classes = cm.shape[0]  # find the number of classes we're dealing with\n",
        "\n",
        "    # Plot the figure and make it pretty\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    cax = ax.matshow(cm, cmap=plt.cm.Blues)  # colors will represent how 'correct' a class is, darker == better\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Are there a list of classes?\n",
        "    if classes:\n",
        "        labels = classes\n",
        "    else:\n",
        "        labels = np.arange(cm.shape[0])\n",
        "\n",
        "    # Label the axes\n",
        "    ax.set(title=\"Confusion Matrix\",\n",
        "           xlabel=\"Predicted label\",\n",
        "           ylabel=\"True label\",\n",
        "           xticks=np.arange(n_classes),  # create enough axis slots for each class\n",
        "           yticks=np.arange(n_classes),\n",
        "           xticklabels=labels,  # axes will labeled with class names (if they exist) or ints\n",
        "           yticklabels=labels)\n",
        "\n",
        "    # Make x-axis labels appear on bottom\n",
        "    ax.xaxis.set_label_position(\"bottom\")\n",
        "    ax.xaxis.tick_bottom()\n",
        "\n",
        "    # Set the threshold for different colors\n",
        "    threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "    # Plot the text on each cell\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "                 size=text_size)"
      ],
      "metadata": {
        "id": "McJSS7IaEQoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the most recent model\n",
        "y_probs = model_14.predict(test_data) # \"probs\" is short for probabilities\n",
        "\n",
        "# View the first 5 predictions\n",
        "y_probs[:5]"
      ],
      "metadata": {
        "id": "w3mZiFApbguf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the predicted class number and label for the first example\n",
        "y_probs[0].argmax(), class_names[y_probs[0].argmax()]"
      ],
      "metadata": {
        "id": "Km53ADa9bjfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all of the predictions from probabilities to labels\n",
        "y_preds = y_probs.argmax(axis=1)\n",
        "\n",
        "# View the first 10 prediction labels\n",
        "y_preds[:10]"
      ],
      "metadata": {
        "id": "6GaTvkJRblRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the non-prettified confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_true=test_labels,\n",
        "                 y_pred=y_preds)"
      ],
      "metadata": {
        "id": "E4x11sWubo4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prettier confusion matrix\n",
        "make_confusion_matrix(y_true=test_labels,\n",
        "                      y_pred=y_preds,\n",
        "                      classes=class_names,\n",
        "                      figsize=(15, 15),\n",
        "                      text_size=10)"
      ],
      "metadata": {
        "id": "yNvrrHL5br9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Create a function for plotting a random image along with its prediction\n",
        "def plot_random_image(model, images, true_labels, classes):\n",
        "  # Setup random integer\n",
        "  i = random.randint(0, len(images))\n",
        "\n",
        "  # Create predictions and targets\n",
        "  target_image = images[i]\n",
        "  pred_probs = model.predict(target_image.reshape(1, 28, 28)) # have to reshape to get into right size for model\n",
        "  pred_label = classes[pred_probs.argmax()]\n",
        "  true_label = classes[true_labels[i]]\n",
        "\n",
        "  # Plot the target image\n",
        "  plt.imshow(target_image, cmap=plt.cm.binary)\n",
        "\n",
        "  # Change the color of the titles depending on if the prediction is right or wrong\n",
        "  if pred_label == true_label:\n",
        "    color = \"green\"\n",
        "  else:\n",
        "    color = \"red\"\n",
        "\n",
        "  # Add xlabel information (prediction/true label)\n",
        "  plt.xlabel(\"Pred: {} {:2.0f}% (True: {})\".format(pred_label,\n",
        "                                                   100*tf.reduce_max(pred_probs),\n",
        "                                                   true_label),\n",
        "             color=color) # set the color to green or red"
      ],
      "metadata": {
        "id": "KLHWGPDcsouY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a random image as well as its prediction\n",
        "plot_random_image(model=model_14,\n",
        "                  images=test_data,\n",
        "                  true_labels=test_labels,\n",
        "                  classes=class_names)"
      ],
      "metadata": {
        "id": "XCKuWyAJsskL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What patterns is our model learning ?"
      ],
      "metadata": {
        "id": "W2J7k0N8swS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_14.layers"
      ],
      "metadata": {
        "id": "BU01OzVuszmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_14.layers[1]"
      ],
      "metadata": {
        "id": "3YOtdp1js4BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the patterns of a layer in our network\n",
        "weights, biases = model_14.layers[1].get_weights()\n",
        "\n",
        "weights, weights.shape"
      ],
      "metadata": {
        "id": "sz8TgmHOs7Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "biases, biases.shape"
      ],
      "metadata": {
        "id": "ccPrD2PgtFLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_14.summary()"
      ],
      "metadata": {
        "id": "offJgtOltG13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# See the inputs and outputs of each layer\n",
        "plot_model(model_14, show_shapes=True)"
      ],
      "metadata": {
        "id": "L6utUvAEtKmS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}